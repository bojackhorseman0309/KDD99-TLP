{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1\n",
    "\n",
    "Estudiantes:\n",
    "\n",
    "- Alonso Araya Calvo\n",
    "- Pedro Soto\n",
    "- Sofia Oviedo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLfMPjjz6Tqf"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lh6x4GjDbzO"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import *\n",
    "from scipy import stats\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.utils import get_file\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from optuna.visualization.matplotlib import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_contour,\n",
    "    plot_slice,\n",
    "    plot_edf,\n",
    ")\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "2pn_P8kZ6a4G",
    "outputId": "0b7a8865-e1a2-4bd7-f826-4dfff161e1ae"
   },
   "outputs": [],
   "source": [
    "#tomado de https://www.kaggle.com/code/wailinnoo/intrusion-detection-system-using-kdd99-dataset\n",
    "try:\n",
    "    path = get_file('kddcup.data_10_percent.gz',\n",
    "                    origin='http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz')\n",
    "except:\n",
    "    print('Error downloading')\n",
    "    raise\n",
    "\n",
    "print(path)\n",
    "\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "# Download from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "pd_data_frame = pd.read_csv(path, header=None)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "pd_data_frame.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]\n",
    "\n",
    "#describe the dataset\n",
    "#transform nominal features using a one hot vector encoding\n",
    "pd_data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWfo9Anw8lIj"
   },
   "source": [
    "# Preprocessing and  Dummy encoding transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyQm_Rkb7j-O"
   },
   "source": [
    "Attacks fall into four main categories:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.   DOS: denial-of-service, e.g. syn flood;\n",
    "2.   R2L: unauthorized access from a remote machine, e.g. guessing password;\n",
    "\n",
    "3. U2R:  unauthorized access to local superuser (root) privileges, e.g., various ``buffer overflow'' attacks;\n",
    "\n",
    "4. probing: surveillance and other probing, e.g., port scanning.\n",
    "\n",
    "\n",
    "It is important to note that the test data is not from the same probability distribution as the training data, and it includes specific attack types not in the training data.  This makes the task more realistic.  Some intrusion experts believe that most novel attacks are variants of known attacks and the \"signature\" of known attacks can be sufficient to catch novel variants.  The datasets contain a total of 24 training attack types, with an additional 14 types in the test data only.\n",
    "\n",
    "Neptune is the most frequent attack in the dataset, consisting in a type of denial-of-service (DoS) attack overwhelming systems with SYN requests (ynchronize request, is a type of network packet used in the TCP handshake to initiate a connection between a client and a server).\n",
    "\n",
    "**In this work we will focus in the detection of backdrop attacks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gc6X0vQv5ad6",
    "outputId": "871f9829-f324-4483-bf8d-ab2bfe15accf"
   },
   "outputs": [],
   "source": [
    "# For now, just drop NA's (rows with missing values), in case there are\n",
    "pd_data_frame.dropna(inplace=True, axis=1)\n",
    "\n",
    "# Checkng for DUPLICATE values\n",
    "pd_data_frame.drop_duplicates(keep='first', inplace=True)\n",
    "print(pd_data_frame.describe())\n",
    "filtered_df = pd_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "IPAlBcwx6PFC",
    "outputId": "f938e77e-5ab4-4035-d81e-3bb39d415216"
   },
   "outputs": [],
   "source": [
    "# distribution of the attack categories (outcome)\n",
    "# Exploratory data analysis\n",
    "plt.figure(figsize=(15, 7))\n",
    "class_distribution = pd_data_frame['outcome'].value_counts()\n",
    "class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of yi in train data')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#normal and neptune are the more prominent classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v8NO_C3d8ox2",
    "outputId": "ce011211-d5af-46c6-951b-189cfdb97f8d"
   },
   "outputs": [],
   "source": [
    "list_nominal_features = [\"flag\", \"protocol_type\", \"service\"]\n",
    "\n",
    "# Apply one-hot encoding to the nominal features\n",
    "df_encoded = pd.get_dummies(filtered_df, columns=list_nominal_features)\n",
    "\n",
    "# Convert boolean columns (from one-hot encoding) to integers (0 or 1) in df_encoded\n",
    "for col in df_encoded.columns:\n",
    "    if df_encoded[col].dtype == 'bool':\n",
    "        df_encoded[col] = df_encoded[col].astype(int)\n",
    "\n",
    "# Display the first few rows of the modified DataFrame to verify\n",
    "print(\"DataFrame with boolean columns converted to integers:\")\n",
    "display(df_encoded.describe())\n",
    "print(\"Columns after nominal attributes encoded: \")\n",
    "for i in df_encoded.columns:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. (30 puntos) Implementacion de un arbol de decision y random forests para clasificar todos los tipos de ataques (scikit learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Genere una funcion split_dataset la cual divida los datos en entrenamiento (70 %), validacion (15 %) y prueba (15 %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, target_column='outcome', test_size=0.15, val_size=0.15, random_state=42, show_sizes=False):\n",
    "    \"\"\"\n",
    "    Función que parte el dataset en conjuntos de entrenamiento, validación y prueba\n",
    "    por medio de los parametros solicitados.\n",
    "    \n",
    "    Parámetros:\n",
    "        df : DataFrame de pandas con los datos del dataset\n",
    "        target_column : Nombre de la columna de las clases en string\n",
    "        test_size : Proporción numerica del conjunto de prueba\n",
    "        val_size : Proporción numerica del conjunto de validación\n",
    "        random_state : Seed para poder reproducir los resultados\n",
    "    \n",
    "    Salida:\n",
    "        tupla con esta forma:\n",
    "            (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n",
    "        X_train: Dataframe con las caracteristicas de entrenamiento\n",
    "        X_val: Dataframe con las caracteristicas de validación\n",
    "        X_test: Dataframe con las caracteristicas de prueba\n",
    "        y_train: Series con las clases de entrenamiento\n",
    "        y_val: Series con las clases de validación\n",
    "        y_test: Series con las clases de prueba\n",
    "    \"\"\"\n",
    "\n",
    "    # Separo las caracteristicas de KDD99 y las clases de outcome\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # En el primer split se separan los datos\n",
    "    # de entrenamiento y validación de los de prueba\n",
    "    # generando el split de prueba\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    # Ajustar el tamaño de validación respecto al conjunto temporal\n",
    "    val_size_adjusted = val_size / (1 - test_size)  # 0.15 / 0.85 ≈ 0.176\n",
    "\n",
    "    # Para este segundo split se separa el conjunto de entrenamiento\n",
    "    # y validación, generando el split de validación y entrenamiento\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=val_size_adjusted,\n",
    "        random_state=random_state,\n",
    "        stratify=y_temp\n",
    "    )\n",
    "    if show_sizes:\n",
    "        print(f\"Tamaño del conjunto completo: {len(df)}\")\n",
    "        print(f\"Entrenamiento: {len(X_train)} ({len(X_train) / len(df) * 100}%)\")\n",
    "        print(f\"Validación: {len(X_val)} ({len(X_val) / len(df) * 100}%)\")\n",
    "        print(f\"Prueba: {len(X_test)} ({len(X_test) / len(df) * 100}%)\")\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(df_encoded, show_sizes=True)\n",
    "\n",
    "# Imprime la distribución de clases para las particiones\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Distribucion de clases en los distintos dataset\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nDistribución en conjunto completo:\")\n",
    "print(df_encoded['outcome'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nDistribución en conjunto de entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nDistribución en conjunto de validación:\")\n",
    "print(y_val.value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nDistribución en conjunto de prueba:\")\n",
    "print(y_test.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 (15 puntos) Entrene un arbol de decision (de scikitlearn) para clasificar los ataques en todas las categorias originales del dataset:\n",
    "\n",
    "a) Optimice la profundidad maxima, cantidad minima de observaciones\n",
    "por particion, y el criterio de pureza usando optuna o weights and\n",
    "biases. Documente los rangos de cada hiper-parametro y justifique la\n",
    "decision por cada uno. Muestre los graficos de ese proceso de optimizacion\n",
    "y seleccione las 3 mejores arquitecturas.\n",
    "\n",
    "b) Compare las tres mejores arquitecturas, para al menos 10 corridas\n",
    "diferentes (particiones), el F1-score promedio para todas las clases\n",
    "y la tasa de falsos positivos promedio para todas las clases, presente\n",
    "medias y desviaciones estandar usando la particion de prueba.\n",
    "Comente los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización con Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_decision_tree(trial):\n",
    "    \"\"\"\n",
    "    Función para optimizar hiperparámetros del árbol de decisión usando Optuna.\n",
    "    \n",
    "    Parámetros:\n",
    "        trial: Objeto de Optuna que sugiere valores para los hiperparámetros\n",
    "        \n",
    "    Retorna:\n",
    "        f1_macro: F1-Score promedio macro en el conjunto de validación\n",
    "    \"\"\"\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 50)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 25)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "\n",
    "    # Crear el modelo con hiperparámetros sugeridos\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        criterion=criterion,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar en conjunto de validación\n",
    "    y_pred = dt.predict(X_val)\n",
    "\n",
    "    # Se calcula el F1-Score promedio macro para todas las clases\n",
    "    f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "    return f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ejecuta optuna para crear las optimizaciones\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # Maximizar F1-score\n",
    "    study_name='DecisionTree_KDD99_Optimization',\n",
    "    storage='sqlite:///decision_tree_optimization.db'\n",
    ")\n",
    "\n",
    "print(\"Iniciando optimización de hiperparámetros con Optuna...\")\n",
    "\n",
    "# 100 pruebas de Optuna que son suficientes para encontrar las mejores arquitecturas\n",
    "n_trials = 100\n",
    "study.optimize(optimize_decision_tree, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Resultados de la optimización con Optuna\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Número total de trials: {len(study.trials)}\")\n",
    "print(f\"Mejor F1-macro encontrado: {study.best_value:.4f}\")\n",
    "print(\"\\nMejores hiperparámetros:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Obtener las 3 mejores arquitecturas\n",
    "best_trials = sorted(study.trials, key=lambda x: x.value if x.value is not None else -1, reverse=True)[:3]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Las 3 mejores arquitecturas encontradas\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "top_3_configs = []\n",
    "for i, trial in enumerate(best_trials, 1):\n",
    "    print(f\"\\nArquitectura #{i}:\")\n",
    "    print(f\"  F1-macro: {trial.value:.4f}\")\n",
    "    print(\"  Hiperparámetros:\")\n",
    "    for param, value in trial.params.items():\n",
    "        print(f\"    {param}: {value}\")\n",
    "\n",
    "    # Guardar configuración para usar los datos en las celdas siguientes\n",
    "    top_3_configs.append({\n",
    "        'params': trial.params,\n",
    "        'f1_score': trial.value,\n",
    "        'rank': i\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadisticas y Graficos de Proceso de Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaciones del proceso de optimización con Optuna\n",
    "\n",
    "# 1) Historia de la optimización\n",
    "plot_optimization_history(study); plt.show()\n",
    "\n",
    "# 2) Importancia de hiperparámetros\n",
    "plot_param_importances(study); plt.show()\n",
    "\n",
    "# 3) Relaciones entre hiperparámetros\n",
    "plot_parallel_coordinate(study); plt.show()\n",
    "plot_contour(\n",
    "    study,\n",
    "    params=['max_depth', 'min_samples_split', 'min_samples_leaf', 'criterion']\n",
    "); plt.show()\n",
    "plot_slice(study); plt.show()\n",
    "\n",
    "# 4) Distribución de valores objetivo \n",
    "plot_edf(study); plt.show()\n",
    "\n",
    "# 5) Comparación visual de las 3 mejores arquitecturas (se mantiene)\n",
    "top_3_f1 = [config['f1_score'] for config in top_3_configs]\n",
    "top_3_names = [f\"Arquitectura #{config['rank']}\" for config in top_3_configs]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(top_3_names, top_3_f1, color=['gold', 'silver', '#CD7F32'], alpha=0.8)\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('Las 3 Mejores Arquitecturas')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for bar, value in zip(bars, top_3_f1):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.0005,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas de la optimización\n",
    "f1_scores = [trial.value for trial in study.trials if trial.value is not None]\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Estadísticas de la optimización\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"F1-score promedio: {np.mean(f1_scores):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(f1_scores):.4f}\")\n",
    "print(f\"F1-score mínimo: {np.min(f1_scores):.4f}\")\n",
    "print(f\"F1-score máximo: {np.max(f1_scores):.4f}\")\n",
    "print(f\"Mejora sobre promedio: {((study.best_value - np.mean(f1_scores)) / np.mean(f1_scores) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion y Evaluacion de las Arquitecturas con Particiones Diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dt_architecture_multiple_runs(params, n_runs=10, random_seeds=None):\n",
    "    \"\"\"\n",
    "    Evalúa una arquitectura de árbol de decisión con múltiples corridas aleatorias.\n",
    "    \n",
    "    Parámetros:\n",
    "        params: Diccionario con hiperparámetros del árbol\n",
    "        n_runs: Número de corridas independientes (default: 10)\n",
    "        random_seeds: Lista de seeds aleatorios (opcional)\n",
    "        \n",
    "    Retorna:\n",
    "        results: Diccionario con todas las metricas recopiladas y parametros utilizados\n",
    "    \"\"\"\n",
    "\n",
    "    if random_seeds is None:\n",
    "        random_seeds = list(range(42, 42 + n_runs))\n",
    "\n",
    "    all_f1_scores = []\n",
    "    all_accuracies = []\n",
    "    all_fpr_rates = []  # Tasas de Falsos Positivos\n",
    "    all_detailed_metrics = []\n",
    "\n",
    "    print(f\"Evaluando arquitectura con {n_runs} corridas independientes...\")\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        seed = random_seeds[run]\n",
    "\n",
    "        # Crear nueva partición aleatoria de datos\n",
    "        X_train_run, X_val_run, X_test_run, y_train_run, y_val_run, y_test_run = split_dataset(\n",
    "            df_encoded, random_state=seed\n",
    "        )\n",
    "\n",
    "        # Crear y entrenar modelo con parámetros dados\n",
    "        dt = DecisionTreeClassifier(**params, random_state=seed)\n",
    "        dt.fit(X_train_run, y_train_run)\n",
    "\n",
    "        # Predicciones en conjunto de prueba\n",
    "        y_pred_test = dt.predict(X_test_run)\n",
    "\n",
    "        # Calcular métricas\n",
    "        f1_macro = f1_score(y_test_run, y_pred_test, average='macro')\n",
    "        accuracy = accuracy_score(y_test_run, y_pred_test)\n",
    "\n",
    "        # Métricas por clase\n",
    "        f1_per_class = f1_score(y_test_run, y_pred_test, average=None, labels=dt.classes_)\n",
    "        precision_per_class, recall_per_class, _, _ = precision_recall_fscore_support(\n",
    "            y_test_run, y_pred_test, average=None, labels=dt.classes_\n",
    "        )\n",
    "\n",
    "        # Calcular matriz de confusión\n",
    "        cm = confusion_matrix(y_test_run, y_pred_test, labels=dt.classes_)\n",
    "\n",
    "        # Calcular tasa de falsos positivos por clase\n",
    "        fpr_per_class = []\n",
    "        for i in range(len(dt.classes_)):\n",
    "            # FPR = FP / (FP + TN)\n",
    "            fp = cm[:, i].sum() - cm[i, i]  # Falsos positivos para clase i\n",
    "            tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])  # Verdaderos negativos\n",
    "            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "            fpr_per_class.append(fpr)\n",
    "\n",
    "        avg_fpr = np.mean(fpr_per_class)\n",
    "\n",
    "        # Recopilar los resultados de la corrida\n",
    "        all_f1_scores.append(f1_macro)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_fpr_rates.append(avg_fpr)\n",
    "        all_detailed_metrics.append({\n",
    "            'run': run + 1,\n",
    "            'seed': seed,\n",
    "            'f1_macro': f1_macro,\n",
    "            'accuracy': accuracy,\n",
    "            'avg_fpr': avg_fpr,\n",
    "            'f1_per_class': f1_per_class,\n",
    "            'precision_per_class': precision_per_class,\n",
    "            'recall_per_class': recall_per_class,\n",
    "            'fpr_per_class': fpr_per_class,\n",
    "            'classes': dt.classes_\n",
    "        })\n",
    "\n",
    "        print(f\"Corrida {run + 1:2d}/{n_runs} - F1: {f1_macro:.4f}, Accuracy: {accuracy:.4f}, FPR: {avg_fpr:.4f}\")\n",
    "\n",
    "    # Calcular estadísticas agregadas\n",
    "    results = {\n",
    "        'n_runs': n_runs,\n",
    "        'params': params,\n",
    "        'f1_scores': all_f1_scores,\n",
    "        'accuracies': all_accuracies,\n",
    "        'fpr_rates': all_fpr_rates,\n",
    "        'detailed_metrics': all_detailed_metrics,\n",
    "        'statistics': {\n",
    "            'f1_mean': np.mean(all_f1_scores),\n",
    "            'f1_std': np.std(all_f1_scores),\n",
    "            'accuracy_mean': np.mean(all_accuracies),\n",
    "            'accuracy_std': np.std(all_accuracies),\n",
    "            'fpr_mean': np.mean(all_fpr_rates),\n",
    "            'fpr_std': np.std(all_fpr_rates)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar las 3 mejores arquitecturas con 10 corridas cada una\n",
    "print(\"=\" * 70)\n",
    "print(\"Evaluación de las 3 mejores arquitecturas con 10 corridas\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for i, config in enumerate(top_3_configs):\n",
    "    print(f\"\\n{'-' * 50}\")\n",
    "    print(f\"Evaluando Arquitectura #{config['rank']}\")\n",
    "    print(\"Hiperparámetros:\")\n",
    "    for param, value in config['params'].items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"{'-' * 50}\")\n",
    "\n",
    "    # Evaluar con 10 corridas independientes usando seeds únicos\n",
    "    results = evaluate_dt_architecture_multiple_runs(\n",
    "        params=config['params'],\n",
    "        n_runs=10,\n",
    "        random_seeds=list(range(100 + i * 10, 110 + i * 10))\n",
    "    )\n",
    "\n",
    "    # Añadir información de las corridas originales\n",
    "    results['architecture_rank'] = config['rank']\n",
    "    results['optimization_f1'] = config['f1_score']\n",
    "    evaluation_results.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"Tabla resumen de resultados - Evaluación de árboles de decisión\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Generar tabla con estadísticas previamente recopiladas\n",
    "summary_data = []\n",
    "for result in evaluation_results:\n",
    "    summary_data.append({\n",
    "        'Arquitectura': f\"#{result['architecture_rank']}\",\n",
    "        'F1-macro Media': f\"{result['statistics']['f1_mean']:.4f}\",\n",
    "        'F1-macro Desviación Estandar': f\"{result['statistics']['f1_std']:.4f}\",\n",
    "        'Accuracy Media': f\"{result['statistics']['accuracy_mean']:.4f}\",\n",
    "        'Accuracy Desviación Estandar': f\"{result['statistics']['accuracy_std']:.4f}\",\n",
    "        'FPR Media': f\"{result['statistics']['fpr_mean']:.4f}\",\n",
    "        'FPR Desviación Estandar': f\"{result['statistics']['fpr_std']:.4f}\",\n",
    "        'max_depth': result['params']['max_depth'],\n",
    "        'min_samples_split': result['params']['min_samples_split'],\n",
    "        'min_samples_leaf': result['params']['min_samples_leaf'],\n",
    "        'criterion': result['params']['criterion']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Comparación de F1-scores con barras de error\n",
    "architectures = [f\"Arq #{r['architecture_rank']}\" for r in evaluation_results]\n",
    "f1_means = [r['statistics']['f1_mean'] for r in evaluation_results]\n",
    "f1_stds = [r['statistics']['f1_std'] for r in evaluation_results]\n",
    "\n",
    "bars1 = axes[0, 0].bar(architectures, f1_means, yerr=f1_stds, capsize=8,\n",
    "                       color=['gold', 'silver', '#CD7F32'], alpha=0.8, edgecolor='black')\n",
    "axes[0, 0].set_ylabel('F1-score')\n",
    "axes[0, 0].set_title('Comparación F1-score (Media ± Desviación Estándar)')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, mean, std in zip(bars1, f1_means, f1_stds):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + std + 0.001,\n",
    "                    f'{mean:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Comparación de tasas de falsos positivos\n",
    "fpr_means = [r['statistics']['fpr_mean'] for r in evaluation_results]\n",
    "fpr_stds = [r['statistics']['fpr_std'] for r in evaluation_results]\n",
    "\n",
    "bars2 = axes[0, 1].bar(architectures, fpr_means, yerr=fpr_stds, capsize=8,\n",
    "                       color=['gold', 'silver', '#CD7F32'], alpha=0.8, edgecolor='black')\n",
    "axes[0, 1].set_ylabel('Tasa de Falsos Positivos')\n",
    "axes[0, 1].set_title('Comparación FPR (Media ± Desviación Estándar)')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, mean, std in zip(bars2, fpr_means, fpr_stds):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + std + 0.0005,\n",
    "                    f'{mean:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Distribuciones de F1-scores (Box plots)\n",
    "f1_data = [r['f1_scores'] for r in evaluation_results]\n",
    "box1 = axes[1, 0].boxplot(f1_data, labels=architectures, patch_artist=True)\n",
    "colors = ['gold', 'silver', '#CD7F32']\n",
    "for patch, color in zip(box1['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.8)\n",
    "axes[1, 0].set_ylabel('F1-score')\n",
    "axes[1, 0].set_title('Distribución de F1-scores por Arquitectura')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Distribuciones de FPR (Box plots)\n",
    "fpr_data = [r['fpr_rates'] for r in evaluation_results]\n",
    "box2 = axes[1, 1].boxplot(fpr_data, labels=architectures, patch_artist=True)\n",
    "for patch, color in zip(box2['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.8)\n",
    "axes[1, 1].set_ylabel('Tasa de Falsos Positivos')\n",
    "axes[1, 1].set_title('Distribución de FPR por Arquitectura')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identificar mejor arquitectura\n",
    "best_arch_idx = np.argmax([r['statistics']['f1_mean'] for r in evaluation_results])\n",
    "best_arch = evaluation_results[best_arch_idx]\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"Arquitectura recomendada\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Mejor arquitectura: #{best_arch['architecture_rank']}\")\n",
    "print(f\"F1-score: {best_arch['statistics']['f1_mean']:.4f} ± {best_arch['statistics']['f1_std']:.4f}\")\n",
    "print(f\"FPR: {best_arch['statistics']['fpr_mean']:.4f} ± {best_arch['statistics']['fpr_std']:.4f}\")\n",
    "print(f\"Accuracy: {best_arch['statistics']['accuracy_mean']:.4f} ± {best_arch['statistics']['accuracy_std']:.4f}\")\n",
    "print(\"\\nHiperparámetros óptimos:\")\n",
    "for param, value in best_arch['params'].items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. (15 puntos) Usando tambien la libreria scikit learn entrene un random forest.\n",
    "\n",
    "a) Optimice con optuna o weights and biases la cantidad de arboles del\n",
    "random forest. Defina el rango de numero de arboles de decision de\n",
    "forma justificada.\n",
    "\n",
    "b) Compare los 2 mejores random forests seleccionados por la herramienta,\n",
    "haciendo 10 corridas diferentes (particiones), el F1-score promedio\n",
    "para todas las clases y la tasa de falsos positivos promedio\n",
    "para todas las clases, presente medias y desviaciones estandar usando\n",
    "la particion de prueba. Comente los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización con Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_random_forest(trial):\n",
    "    \"\"\"\n",
    "    Función para optimizar solo los n_estimators del Random Forest usando Optuna.\n",
    "    \n",
    "    Parámetros:\n",
    "        trial: Objeto de Optuna que sugiere valores para n_estimators\n",
    "        \n",
    "    Retorna:\n",
    "        f1_macro: F1-Score promedio macro en el conjunto de validación\n",
    "    \"\"\"\n",
    "    \n",
    "    # Rango de numero de arboles\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 300)\n",
    "    \n",
    "    # Creacion de RandomForest\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar en conjunto de validación\n",
    "    y_pred = rf.predict(X_val)\n",
    "    \n",
    "    # Calcular F1-Score promedio macro para todas las clases\n",
    "    f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    return f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar optimización de Random Forest\n",
    "study_rf = optuna.create_study(\n",
    "    direction='maximize',  # Maximizar F1-score\n",
    "    study_name='RandomForest_KDD99_Optimization',\n",
    "    storage='sqlite:///random_forest_optimization.db'\n",
    ")\n",
    "\n",
    "print(\"Iniciando optimización de hiperparámetros de Random Forest con Optuna...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 50 pruebas de optimización debido al alto tiempo de ejecucion y computo\n",
    "# utilizado en comparacion a entrenar un arbol de decision.\n",
    "n_trials_rf = 50\n",
    "study_rf.optimize(objective_random_forest, n_trials=n_trials_rf, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Resultados de la optimización de Random Forest con Optuna\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Número total de trials: {len(study_rf.trials)}\")\n",
    "print(f\"Mejor F1-macro encontrado: {study_rf.best_value:.4f}\")\n",
    "print(\"\\nMejores hiperparámetros:\")\n",
    "for param, value in study_rf.best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Obtener los 2 mejores Random Forests\n",
    "best_trials_rf = sorted(study_rf.trials, key=lambda x: x.value if x.value is not None else -1, reverse=True)[:2]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Los 2 mejores Random Forests encontrados\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "top_2_rf_configs = []\n",
    "for i, trial in enumerate(best_trials_rf, 1):\n",
    "    print(f\"\\nRandom Forest #{i}:\")\n",
    "    print(f\"  F1-macro: {trial.value:.4f}\")\n",
    "    print(\"  Hiperparámetros:\")\n",
    "    for param, value in trial.params.items():\n",
    "        print(f\"    {param}: {value}\")\n",
    "\n",
    "    # Guardar configuración\n",
    "    top_2_rf_configs.append({\n",
    "        'params': trial.params,\n",
    "        'f1_score': trial.value,\n",
    "        'rank': i\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizacion del Proceso de Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaciones del proceso de optimización con Optuna\n",
    "\n",
    "# 1) Historia de la optimización de Random Forest\n",
    "plot_optimization_history(study_rf); plt.show()\n",
    "\n",
    "# 2) Importancia de hiperparámetros de Random Forest\n",
    "plot_param_importances(study_rf); plt.show()\n",
    "\n",
    "# 3) Análisis slice de cada hiperparámetro\n",
    "plot_slice(study_rf); plt.show()\n",
    "\n",
    "# 4) Distribución empírica de valores objetivo (EDF)\n",
    "plot_edf(study_rf); plt.show()\n",
    "\n",
    "# 5) Comparación visual de los 2 mejores Random Forests\n",
    "top_2_f1_rf = [config['f1_score'] for config in top_2_rf_configs]\n",
    "top_2_names_rf = [f\"RF #{config['rank']}\" for config in top_2_rf_configs]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(top_2_names_rf, top_2_f1_rf, color=['gold', 'silver'], alpha=0.8, edgecolor='black')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('Los 2 Mejores Random Forests')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Añadir valores sobre las barras\n",
    "for bar, value in zip(bars, top_2_f1_rf):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.0005,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas de la optimización RF\n",
    "f1_scores_rf = [trial.value for trial in study_rf.trials if trial.value is not None]\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Estadísticas de la optimización de Random Forest\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"F1-score promedio: {np.mean(f1_scores_rf):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(f1_scores_rf):.4f}\")\n",
    "print(f\"F1-score mínimo: {np.min(f1_scores_rf):.4f}\")\n",
    "print(f\"F1-score máximo: {np.max(f1_scores_rf):.4f}\")\n",
    "print(f\"Mejora sobre promedio: {((study_rf.best_value - np.mean(f1_scores_rf)) / np.mean(f1_scores_rf) * 100):.2f}%\")\n",
    "\n",
    "# Análisis específico de n_estimators encontrados\n",
    "n_estimators_values = [trial.params.get('n_estimators', 0) for trial in study_rf.trials]\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"Analisis de numero de arboles\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Rango explorado: {min(n_estimators_values)} - {max(n_estimators_values)}\")\n",
    "print(f\"Promedio de trials: {np.mean(n_estimators_values):.1f}\")\n",
    "print(f\"Mediana de trials: {np.median(n_estimators_values):.1f}\")\n",
    "print(f\"Desviación estándar: {np.std(n_estimators_values):.1f}\")\n",
    "print(f\"Mejor configuración: {study_rf.best_params['n_estimators']} árboles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion de Mejores Arquitecturas con Particiones Independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rf_architecture_multiple_runs(params, n_runs=10, random_seeds=None):\n",
    "    \"\"\"\n",
    "    Evalúa una arquitectura de Random Forest con múltiples corridas aleatorias.\n",
    "    \n",
    "    Parámetros:\n",
    "        params: Diccionario con hiperparámetros del Random Forest\n",
    "        n_runs: Número de corridas independientes\n",
    "        random_seeds: Lista de seeds aleatorios\n",
    "        \n",
    "    Retorna:\n",
    "        results: Diccionario con métricas recopiladas y parametros utilizados\n",
    "    \"\"\"\n",
    "\n",
    "    if random_seeds is None:\n",
    "        random_seeds = list(range(200, 200 + n_runs))\n",
    "\n",
    "    all_f1_scores = []\n",
    "    all_accuracies = []\n",
    "    all_fpr_rates = []\n",
    "    all_detailed_metrics = []\n",
    "\n",
    "    print(f\"Evaluando Random Forest con {n_runs} corridas independientes...\")\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        seed = random_seeds[run]\n",
    "\n",
    "        # Crear nueva partición aleatoria de datos\n",
    "        X_train_run, X_val_run, X_test_run, y_train_run, y_val_run, y_test_run = split_dataset(\n",
    "            df_encoded, random_state=seed\n",
    "        )\n",
    "\n",
    "        # Crear y entrenar Random Forest con parámetros dados\n",
    "        rf = RandomForestClassifier(**params, random_state=seed, n_jobs=-1)\n",
    "        rf.fit(X_train_run, y_train_run)\n",
    "\n",
    "        # Predicciones en conjunto de prueba\n",
    "        y_pred_test = rf.predict(X_test_run)\n",
    "\n",
    "        # Calcular métricas\n",
    "        f1_macro = f1_score(y_test_run, y_pred_test, average='macro')\n",
    "        accuracy = accuracy_score(y_test_run, y_pred_test)\n",
    "\n",
    "        # Métricas por clase\n",
    "        f1_per_class = f1_score(y_test_run, y_pred_test, average=None, labels=rf.classes_)\n",
    "        precision_per_class, recall_per_class, _, _ = precision_recall_fscore_support(\n",
    "            y_test_run, y_pred_test, average=None, labels=rf.classes_\n",
    "        )\n",
    "\n",
    "        # Calcular matriz de confusión\n",
    "        cm = confusion_matrix(y_test_run, y_pred_test, labels=rf.classes_)\n",
    "\n",
    "        # Calcular tasa de falsos positivos por clase\n",
    "        fpr_per_class = []\n",
    "        for i in range(len(rf.classes_)):\n",
    "            fp = cm[:, i].sum() - cm[i, i]  # Falsos positivos para clase i\n",
    "            tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])  # Verdaderos negativos\n",
    "            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "            fpr_per_class.append(fpr)\n",
    "\n",
    "        avg_fpr = np.mean(fpr_per_class)\n",
    "\n",
    "        # Recopilar resultados de la corrida\n",
    "        all_f1_scores.append(f1_macro)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_fpr_rates.append(avg_fpr)\n",
    "        all_detailed_metrics.append({\n",
    "            'run': run + 1,\n",
    "            'seed': seed,\n",
    "            'f1_macro': f1_macro,\n",
    "            'accuracy': accuracy,\n",
    "            'avg_fpr': avg_fpr,\n",
    "            'f1_per_class': f1_per_class,\n",
    "            'precision_per_class': precision_per_class,\n",
    "            'recall_per_class': recall_per_class,\n",
    "            'fpr_per_class': fpr_per_class,\n",
    "            'classes': rf.classes_\n",
    "        })\n",
    "\n",
    "        print(f\"Corrida {run + 1:2d}/{n_runs} - F1: {f1_macro:.4f}, Accuracy: {accuracy:.4f}, FPR: {avg_fpr:.4f}\")\n",
    "\n",
    "    # Calcular estadísticas agregadas\n",
    "    results = {\n",
    "        'n_runs': n_runs,\n",
    "        'params': params,\n",
    "        'f1_scores': all_f1_scores,\n",
    "        'accuracies': all_accuracies,\n",
    "        'fpr_rates': all_fpr_rates,\n",
    "        'detailed_metrics': all_detailed_metrics,\n",
    "        'statistics': {\n",
    "            'f1_mean': np.mean(all_f1_scores),\n",
    "            'f1_std': np.std(all_f1_scores),\n",
    "            'accuracy_mean': np.mean(all_accuracies),\n",
    "            'accuracy_std': np.std(all_accuracies),\n",
    "            'fpr_mean': np.mean(all_fpr_rates),\n",
    "            'fpr_std': np.std(all_fpr_rates)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar los 2 mejores Random Forests con 10 corridas cada uno\n",
    "print(\"=\" * 70)\n",
    "print(\"Evaluación de los 2 mejores Random Forests con 10 corridas\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rf_evaluation_results = []\n",
    "\n",
    "for i, config in enumerate(top_2_rf_configs):\n",
    "    print(f\"\\n{'-' * 50}\")\n",
    "    print(f\"Evaluando Random Forest #{config['rank']}\")\n",
    "    print(\"Hiperparámetros:\")\n",
    "    for param, value in config['params'].items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"{'-' * 50}\")\n",
    "\n",
    "    # Evaluar con 10 corridas independientes usando seeds únicos\n",
    "    results = evaluate_rf_architecture_multiple_runs(\n",
    "        params=config['params'],\n",
    "        n_runs=10,\n",
    "        random_seeds=list(range(300 + i * 10, 310 + i * 10))  # Seeds únicos para cada RF\n",
    "    )\n",
    "\n",
    "    # Añadir información de corridas originales\n",
    "    results['architecture_rank'] = config['rank']\n",
    "    results['optimization_f1'] = config['f1_score']\n",
    "    rf_evaluation_results.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla resumen para Random Forests\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"Resumen Evaluacion Random Forests\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Generar tabla con estadísticas detalladas para RF\n",
    "rf_summary_data = []\n",
    "for result in rf_evaluation_results:\n",
    "    rf_summary_data.append({\n",
    "        'Random Forest': f\"#{result['architecture_rank']}\",\n",
    "        'n_estimators': result['params']['n_estimators'],\n",
    "        'F1-macro Media': f\"{result['statistics']['f1_mean']:.4f}\",\n",
    "        'F1-macro Desv Std': f\"{result['statistics']['f1_std']:.4f}\",\n",
    "        'Accuracy Media': f\"{result['statistics']['accuracy_mean']:.4f}\",\n",
    "        'Accuracy Desv Std': f\"{result['statistics']['accuracy_std']:.4f}\",\n",
    "        'FPR Media': f\"{result['statistics']['fpr_mean']:.4f}\",\n",
    "        'FPR Desv Std': f\"{result['statistics']['fpr_std']:.4f}\",\n",
    "        'F1 Optimización': f\"{result['optimization_f1']:.4f}\"\n",
    "    })\n",
    "\n",
    "rf_summary_df = pd.DataFrame(rf_summary_data)\n",
    "print(rf_summary_df.to_string(index=False))\n",
    "\n",
    "# Visualizaciones comparativas detalladas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Comparación F1-scores RF con barras de error\n",
    "rf_architectures = [f\"RF #{r['architecture_rank']}\\n(n={r['params']['n_estimators']})\" \n",
    "                   for r in rf_evaluation_results]\n",
    "rf_f1_means = [r['statistics']['f1_mean'] for r in rf_evaluation_results]\n",
    "rf_f1_stds = [r['statistics']['f1_std'] for r in rf_evaluation_results]\n",
    "\n",
    "bars1 = axes[0, 0].bar(rf_architectures, rf_f1_means, yerr=rf_f1_stds, capsize=8,\n",
    "                       color=['gold', 'silver'], alpha=0.8, edgecolor='black')\n",
    "axes[0, 0].set_ylabel('F1-score')\n",
    "axes[0, 0].set_title('Comparación F1-score Random Forests\\n(Media ± Desviación Estándar)')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Añadir valores sobre las barras\n",
    "for bar, mean, std in zip(bars1, rf_f1_means, rf_f1_stds):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + std + 0.001,\n",
    "                    f'{mean:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Comparación FPR RF\n",
    "rf_fpr_means = [r['statistics']['fpr_mean'] for r in rf_evaluation_results]\n",
    "rf_fpr_stds = [r['statistics']['fpr_std'] for r in rf_evaluation_results]\n",
    "\n",
    "bars2 = axes[0, 1].bar(rf_architectures, rf_fpr_means, yerr=rf_fpr_stds, capsize=8,\n",
    "                       color=['gold', 'silver'], alpha=0.8, edgecolor='black')\n",
    "axes[0, 1].set_ylabel('Tasa de Falsos Positivos')\n",
    "axes[0, 1].set_title('Comparación FPR Random Forests\\n(Media ± Desviación Estándar)')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, mean, std in zip(bars2, rf_fpr_means, rf_fpr_stds):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + std + 0.0005,\n",
    "                    f'{mean:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Box plots F1-scores RF\n",
    "rf_f1_data = [r['f1_scores'] for r in rf_evaluation_results]\n",
    "box1 = axes[1, 0].boxplot(rf_f1_data, labels=[f\"RF #{r['architecture_rank']}\" \n",
    "                                             for r in rf_evaluation_results], patch_artist=True)\n",
    "colors_rf = ['gold', 'silver']\n",
    "for patch, color in zip(box1['boxes'], colors_rf):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.8)\n",
    "axes[1, 0].set_ylabel('F1-score')\n",
    "axes[1, 0].set_title('Distribución F1-scores Random Forests')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Box plots FPR RF\n",
    "rf_fpr_data = [r['fpr_rates'] for r in rf_evaluation_results]\n",
    "box2 = axes[1, 1].boxplot(rf_fpr_data, labels=[f\"RF #{r['architecture_rank']}\" \n",
    "                                              for r in rf_evaluation_results], patch_artist=True)\n",
    "for patch, color in zip(box2['boxes'], colors_rf):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.8)\n",
    "axes[1, 1].set_ylabel('Tasa de Falsos Positivos')\n",
    "axes[1, 1].set_title('Distribución FPR Random Forests')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Análisis Estadístico y Comentarios de Resultados\n",
    "\n",
    "# Análisis estadístico de diferencias entre RF\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANÁLISIS ESTADÍSTICO DE DIFERENCIAS ENTRE RANDOM FORESTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "rf_f1_1 = rf_evaluation_results[0]['f1_scores']\n",
    "rf_f1_2 = rf_evaluation_results[1]['f1_scores']\n",
    "\n",
    "try:\n",
    "    # t-test pareado para comparar los dos RF\n",
    "    t_stat_rf, p_val_rf = stats.ttest_rel(rf_f1_1, rf_f1_2)\n",
    "    print(f\"Prueba t pareada entre RF #1 y RF #2:\")\n",
    "    print(f\"  t-statistic: {t_stat_rf:.4f}\")\n",
    "    print(f\"  p-value: {p_val_rf:.6f}\")\n",
    "    print(f\"  Diferencias significativas: {'Sí' if p_val_rf < 0.05 else 'No'} (α=0.05)\")\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt((np.var(rf_f1_1) + np.var(rf_f1_2)) / 2)\n",
    "    cohens_d = (np.mean(rf_f1_1) - np.mean(rf_f1_2)) / pooled_std\n",
    "    print(f\"  Effect size (Cohen's d): {cohens_d:.4f}\")\n",
    "    \n",
    "    effect_interpretation = \"pequeño\" if abs(cohens_d) < 0.2 else \"medio\" if abs(cohens_d) < 0.8 else \"grande\"\n",
    "    print(f\"  Interpretación del efecto: {effect_interpretation}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error en análisis estadístico: {e}\")\n",
    "\n",
    "# Análisis de estabilidad RF\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"ANÁLISIS DE ESTABILIDAD DE RANDOM FORESTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, result in enumerate(rf_evaluation_results):\n",
    "    rf_num = result['architecture_rank']\n",
    "    n_trees = result['params']['n_estimators']\n",
    "    f1_cv = result['statistics']['f1_std'] / result['statistics']['f1_mean']\n",
    "    fpr_cv = result['statistics']['fpr_std'] / result['statistics']['fpr_mean'] if result['statistics']['fpr_mean'] > 0 else 0\n",
    "\n",
    "    print(f\"\\nRandom Forest #{rf_num} (n_estimators={n_trees}):\")\n",
    "    print(f\"  Coeficiente de variación F1: {f1_cv:.4f} ({'Muy estable' if f1_cv < 0.005 else 'Estable' if f1_cv < 0.01 else 'Moderada' if f1_cv < 0.02 else 'Inestable'})\")\n",
    "    print(f\"  Coeficiente de variación FPR: {fpr_cv:.4f}\")\n",
    "\n",
    "    # Intervalos de confianza (95%)\n",
    "    f1_ci_lower = result['statistics']['f1_mean'] - 1.96 * result['statistics']['f1_std']\n",
    "    f1_ci_upper = result['statistics']['f1_mean'] + 1.96 * result['statistics']['f1_std']\n",
    "    print(f\"  Intervalo confianza F1 (95%): [{f1_ci_lower:.4f}, {f1_ci_upper:.4f}]\")\n",
    "    \n",
    "    fpr_ci_lower = result['statistics']['fpr_mean'] - 1.96 * result['statistics']['fpr_std']\n",
    "    fpr_ci_upper = result['statistics']['fpr_mean'] + 1.96 * result['statistics']['fpr_std']\n",
    "    print(f\"  Intervalo confianza FPR (95%): [{max(0, fpr_ci_lower):.4f}, {fpr_ci_upper:.4f}]\")\n",
    "\n",
    "# Identificar mejor Random Forest\n",
    "best_rf_idx = np.argmax([r['statistics']['f1_mean'] for r in rf_evaluation_results])\n",
    "best_rf = rf_evaluation_results[best_rf_idx]\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"RANDOM FOREST RECOMENDADO\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Mejor Random Forest: #{best_rf['architecture_rank']}\")\n",
    "print(f\"Configuración óptima: n_estimators = {best_rf['params']['n_estimators']}\")\n",
    "print(f\"F1-score: {best_rf['statistics']['f1_mean']:.4f} ± {best_rf['statistics']['f1_std']:.4f}\")\n",
    "print(f\"FPR: {best_rf['statistics']['fpr_mean']:.4f} ± {best_rf['statistics']['fpr_std']:.4f}\")\n",
    "print(f\"Accuracy: {best_rf['statistics']['accuracy_mean']:.4f} ± {best_rf['statistics']['accuracy_std']:.4f}\")\n",
    "\n",
    "# Análisis de eficiencia computacional\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"ANÁLISIS DE EFICIENCIA COMPUTACIONAL\")\n",
    "print(\"=\" * 80)\n",
    "for result in rf_evaluation_results:\n",
    "    n_trees = result['params']['n_estimators']\n",
    "    f1_mean = result['statistics']['f1_mean']\n",
    "    \n",
    "    # Estimación relativa de complejidad (linear con n_estimators)\n",
    "    complexity_ratio = n_trees / min([r['params']['n_estimators'] for r in rf_evaluation_results])\n",
    "    efficiency_score = f1_mean / complexity_ratio  # F1 per unit complexity\n",
    "    \n",
    "    print(f\"RF #{result['architecture_rank']} (n={n_trees}):\")\n",
    "    print(f\"  Complejidad relativa: {complexity_ratio:.2f}x\")\n",
    "    print(f\"  Eficiencia (F1/complejidad): {efficiency_score:.4f}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"COMENTARIOS SOBRE LOS RESULTADOS DE RANDOM FOREST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Generar comentarios dinámicos basados en resultados\n",
    "best_n = best_rf['params']['n_estimators']\n",
    "best_f1 = best_rf['statistics']['f1_mean']\n",
    "best_fpr = best_rf['statistics']['fpr_mean']\n",
    "\n",
    "print(f\"\"\"\n",
    "ANÁLISIS DE RENDIMIENTO DE RANDOM FOREST:\n",
    "\n",
    "1. EFECTIVIDAD DEL NÚMERO DE ÁRBOLES:\n",
    "   • Configuración óptima: {best_n} árboles\n",
    "   • F1-score logrado: {best_f1:.4f} ({'excelente' if best_f1 > 0.995 else 'muy bueno' if best_f1 > 0.99 else 'bueno'})\n",
    "   • Tasa de falsos positivos: {best_fpr:.4f} ({'muy baja' if best_fpr < 0.005 else 'baja' if best_fpr < 0.01 else 'moderada'})\n",
    "\n",
    "2. ANÁLISIS DEL NÚMERO ÓPTIMO DE ÁRBOLES:\n",
    "   • {'Configuración conservadora' if best_n < 100 else 'Configuración moderada' if best_n < 200 else 'Configuración intensiva'}\n",
    "   • {'Eficiente computacionalmente' if best_n < 150 else 'Balance rendimiento-eficiencia' if best_n < 250 else 'Enfoque en máximo rendimiento'}\n",
    "   • {'Apropiado para sistemas en tiempo real' if best_n < 100 else 'Adecuado para sistemas offline' if best_n > 200 else 'Versátil para ambos casos'}\n",
    "\n",
    "3. ESTABILIDAD Y ROBUSTEZ:\n",
    "   • Variabilidad F1: {best_rf['statistics']['f1_std']:.4f} ({'muy estable' if best_rf['statistics']['f1_std'] < 0.002 else 'estable' if best_rf['statistics']['f1_std'] < 0.005 else 'moderadamente variable'})\n",
    "   • Consistencia entre particiones: {'Alta' if best_rf['statistics']['f1_std'] < 0.003 else 'Media'}\n",
    "   • Confiabilidad para producción: {'Alta' if best_rf['statistics']['f1_std'] < 0.005 else 'Media'}\n",
    "\n",
    "4. COMPARACIÓN ENTRE CONFIGURACIONES:\n",
    "   • Diferencia de rendimiento: {abs(rf_f1_means[0] - rf_f1_means[1]):.4f}\n",
    "   • {'Configuraciones muy similares' if abs(rf_f1_means[0] - rf_f1_means[1]) < 0.001 else 'Diferencia notable' if abs(rf_f1_means[0] - rf_f1_means[1]) > 0.005 else 'Diferencia moderada'}\n",
    "   • Recomendación: {'Usar configuración más eficiente' if abs(rf_f1_means[0] - rf_f1_means[1]) < 0.001 else 'Usar configuración con mejor rendimiento'}\n",
    "\n",
    "5. APLICABILIDAD EN DETECCIÓN DE INTRUSIONES:\n",
    "   • Adecuado para IDS en tiempo real: {'Sí' if best_n < 150 and best_fpr < 0.01 else 'Con limitaciones' if best_n > 200 else 'Moderadamente'}\n",
    "   • Tasa de falsas alarmas: {'Muy baja, apropiada para entornos críticos' if best_fpr < 0.005 else 'Baja, apropiada para uso general'}\n",
    "   • Balance precision-recall: {'Óptimo para detección de ataques diversos' if best_f1 > 0.995 else 'Bueno para la mayoría de casos'}\n",
    "\n",
    "6. JUSTIFICACIÓN DEL RANGO UTILIZADO:\n",
    "   • El rango [10, 300] demostró ser apropiado\n",
    "   • Valor óptimo {best_n} {'confirma límites conservadores' if best_n < 100 else 'valida rango medio' if best_n < 200 else 'justifica límite superior'}\n",
    "   • {'No se observó plateau significativo' if best_n > 200 else 'Plateau alcanzado en rango medio' if best_n > 100 else 'Configuración eficiente encontrada'}\n",
    "\n",
    "RECOMENDACIÓN FINAL:\n",
    "Random Forest #{best_rf['architecture_rank']} con {best_n} árboles es la configuración\n",
    "óptima, proporcionando F1-score de {best_f1:.4f} con baja tasa de falsos positivos\n",
    "({best_fpr:.4f}), siendo {'altamente recomendado' if best_f1 > 0.995 and best_fpr < 0.005 else 'recomendado'}\n",
    "para sistemas de detección de intrusiones en el dataset KDD99.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación entre mejor árbol de decisión y mejor Random Forest\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"Comparación: Mejor Árbol de Decisión vs Mejor Random Forest\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verificar si existe la variable best_arch de la sección anterior de árboles de decisión\n",
    "try:\n",
    "    print(\"RENDIMIENTO:\")\n",
    "    print(f\"  Árbol de Decisión  - F1: {best_arch['statistics']['f1_mean']:.4f} ± {best_arch['statistics']['f1_std']:.4f}\")\n",
    "    print(f\"  Random Forest      - F1: {best_rf['statistics']['f1_mean']:.4f} ± {best_rf['statistics']['f1_std']:.4f}\")\n",
    "    print(f\"  Mejora RF vs Árbol: {((best_rf['statistics']['f1_mean'] - best_arch['statistics']['f1_mean']) / best_arch['statistics']['f1_mean'] * 100):+.2f}%\")\n",
    "    \n",
    "    print(f\"\\nTASA DE FALSOS POSITIVOS:\")\n",
    "    print(f\"  Árbol de Decisión  - FPR: {best_arch['statistics']['fpr_mean']:.4f} ± {best_arch['statistics']['fpr_std']:.4f}\")\n",
    "    print(f\"  Random Forest      - FPR: {best_rf['statistics']['fpr_mean']:.4f} ± {best_rf['statistics']['fpr_std']:.4f}\")\n",
    "    print(f\"  Reducción FPR: {((best_arch['statistics']['fpr_mean'] - best_rf['statistics']['fpr_mean']) / best_arch['statistics']['fpr_mean'] * 100):+.2f}%\")\n",
    "    \n",
    "    print(f\"\\nCOMPLEJIDAD COMPUTACIONAL:\")\n",
    "    print(f\"  Árbol de Decisión: {best_arch['params']['max_depth']} niveles de profundidad\")\n",
    "    print(f\"  Random Forest: {best_rf['params']['n_estimators']} árboles\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"No se puede comparar con árboles de decisión (variable best_arch no encontrada)\")\n",
    "    print(\"Ejecute primero la sección de árboles de decisión para hacer la comparación\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"Comentarios sobre los resultados de Random Forest\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "ANÁLISIS DE RENDIMIENTO DE RANDOM FOREST:\n",
    "\n",
    "1. EFECTIVIDAD DEL ENSEMBLE:\n",
    "   - Los Random Forests muestran rendimiento {'superior' if best_rf['statistics']['f1_mean'] > 0.995 else 'excelente'} (F1 > {best_rf['statistics']['f1_mean']:.3f})\n",
    "   - {'Reducción significativa' if best_rf['statistics']['fpr_mean'] < 0.005 else 'Control efectivo'} de falsos positivos\n",
    "   - Estabilidad {'muy alta' if best_rf['statistics']['f1_std'] < 0.002 else 'alta'} entre diferentes particiones\n",
    "\n",
    "2. HIPERPARÁMETROS ÓPTIMOS ENCONTRADOS:\n",
    "   - n_estimators = {best_rf['params']['n_estimators']}: {'Suficiente para capturar patrones complejos' if best_rf['params']['n_estimators'] >= 100 else 'Equilibrio entre rendimiento y eficiencia'}\n",
    "\n",
    "3. VENTAJAS OBSERVADAS:\n",
    "   - Robustez ante overfitting por efecto ensemble\n",
    "   - Manejo natural de características irrelevantes\n",
    "   - Estimación de importancia de características\n",
    "   - {'Paralelización eficiente' if best_rf['params'].get('n_jobs', 1) == -1 else 'Procesamiento secuencial'}\n",
    "\n",
    "4. APLICABILIDAD EN DETECCIÓN DE INTRUSIONES:\n",
    "   - Excelente para detección en tiempo real (baja latencia de predicción)\n",
    "   - Tasa de falsas alarmas muy baja ({'<' if best_rf['statistics']['fpr_mean'] < 0.01 else '≈'}{best_rf['statistics']['fpr_mean']:.3f})\n",
    "   - Alta precisión reduce ataques no detectados\n",
    "   - Interpretabilidad mediante importancia de características\n",
    "\n",
    "5. JUSTIFICACIÓN DE RANGO DE n_estimators:\n",
    "   - Rango [10, 300] demostró ser apropiado\n",
    "   - Valor óptimo {best_rf['params']['n_estimators']} {'en rango medio' if 50 <= best_rf['params']['n_estimators'] <= 200 else 'en extremo del rango'}\n",
    "   - {'No se observó mejora significativa' if best_rf['params']['n_estimators'] < 200 else 'Se beneficia de mayor ensemble'} con más árboles\n",
    "   \n",
    "6. ESTABILIDAD Y CONFIABILIDAD:\n",
    "   - Coeficiente de variación: {(best_rf['statistics']['f1_std'] / best_rf['statistics']['f1_mean']):.4f}\n",
    "   - {'Muy estable' if (best_rf['statistics']['f1_std'] / best_rf['statistics']['f1_mean']) < 0.005 else 'Estable'} entre particiones diferentes\n",
    "   - Intervalos de confianza estrechos indican alta confiabilidad\n",
    "\n",
    "RECOMENDACIÓN:\n",
    "Random Forest #{best_rf['architecture_rank']} es la configuración óptima encontrada, \n",
    "proporcionando el mejor balance entre rendimiento, estabilidad y eficiencia computacional\n",
    "para la detección de intrusiones en el dataset KDD99.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
